\Sexpr{set_parent('ISIwithR.Rnw')}

\setcounter{chapter}{0}
\Chapter{Significance: How strong is the evidence?}


\section{Introduction to Chance Models}

\subsection*{Example 1.1: Can Dolphins Communicate?}

\subsubsection*{The Chance Model}

<<Figure1.2>>=
rflip(n = 16, prob = 0.5)    # a sequence of 16 coin flips
@
<<Figure1.3>>=
rflip(n = 16, prob = 0.5)    # another sequence of 16 coin flips
@

\subsubsection*{Using and evaluating the coin flip chance model}

<<Figure1.4, cache=TRUE>>=
Coin.sim <- do(1000) * rflip(16, 0.5)    # 1000 samples, each of size 16 and proportion 0.5
head(Coin.sim, 3)
dotPlot(~ heads, data = Coin.sim, width = 1, cex = 3)
@

\subsubsection*{Another Doris and Buzz study}

%Figure 1.5 bargraph (pp.11)

<<Figure1.6, cache=TRUE>>=
Coin.sim2 <- do(1000) * rflip(28, 0.5)
head(Coin.sim2, 3)
dotPlot(~ heads, data = Coin.sim2, width = 1, cex = 3, groups = (heads == 16))
@
Notice the way we defined \argument{groups} as \option{(groups = (heads == 16))} in order to differentiate the observations where \variable{heads} equals 16.  The 
\verb&==& operator means ``are equal to".
(We could also have used \option{groups = (heads != 16)}  
and the colors would be reversed.)

\subsection*{Exploration 1.1: Can Dogs Understand Human Cues?}

% Exploration1.1.5 bargraph (pp.16)

\subsubsection*{The Chance Model}

<<Exploration1.1.13, cache=TRUE>>=
Harley.sim <- do(1) * rflip(10, 0.5)
Harley.sim
Class.sim <- do(30) * rflip(10, 0.5)
head(Class.sim, 3)
dotPlot(~ heads, data = Class.sim, width = 1, cex = 0.5)
@

<<Exploration1.1.14, cache=TRUE>>=
Harley.sim2 <- do(1000) * rflip(10, 0.5)
head(Harley.sim2, 3)
dotPlot(~ heads, data = Harley.sim2, width = 1, cex = 3, groups = (heads == 9))
@

\subsubsection*{Another Study}

<<Exploration1.1.23>>=
dotPlot(~ heads, data = Harley.sim2, width = 1, cex = 3, groups = (heads == 6))
@


\section{Measuring the Strength of Evidence}

\subsection*{Example 1.2: Rock Paper Scissors}

\begin{enumerate}
  \item
    $H_0$: $\pi = 1/3$
    
    $H_a$: $\pi < 1/3$
    
    Test statistic:  $\hat p = 0.167$ (the sample proportion of 1/6)
	\item
		We simulate a world in which $\pi = 1/3$:
<<Figure1.7, cache=TRUE>>=
RPS.null <- do(1000) * rflip(12, 1/3)
head(RPS.null, 3)
dotPlot(~ prop, data = RPS.null, width = 1/12, cex = 3)
@
  \item
    Strength of evidence:

    For the \term{p-value}, you can use the \function{prop()} function and input \option{(prop <= 1/6)} to find the proportion of samples that is less than or equal to the observed proportion in the data set \dataframe{RPS.null}.
<<Figure1.8>>=
dotPlot(~ prop, data = RPS.null, cex = 3, width = 1/12, groups = (prop <= 1/6))
prop(~ (prop <= 1/6), data = RPS.null)
@
\end{enumerate}

\subsubsection{Conclusions}

<<Figure1.9>>=
dotPlot(~ prop, data = RPS.null, cex = 3, width = 1/12, groups = (prop <= 1/12))
prop(~ (prop <= 1/12), data = RPS.null)
@

\subsection*{Exploration 1.2: Tasting Water}

\begin{enumerate}
  \item
    $H_0$: $\pi = 1/4$
    
    $H_a$: $\pi < 1/4$
    
    Test statistic:  $\hat p = 0.111$ (the sample proportion of 3/27)
  \item
		We simulate a world in which $\pi = 1/4$:
<<Exploration1.2.18, cache=TRUE>>=
Tap.sample <- do(1) * rflip(27, 1/4)
Tap.sample
Tap.null <- do(1000) * rflip(27, 1/4)
head(Tap.null, 3)
dotPlot(~ prop, data = Tap.null, width = 1/27, cex = 3, groups = (prop <= 3/27))
@
  \item
    Strength of evidence:
<<Exploration1.2.20>>=
prop(~ (prop <= 3/27), data = Tap.null)
@
\end{enumerate}

\subsubsection*{Alternate Analysis}

\begin{enumerate}
  \item
    $H_0$: $\pi = 3/4$
    
    $H_a$: $\pi > 3/4$
    
    Test statistic:  $\hat p = 0.889$ (the sample proportion of 24/27)
  \item
  	We simulate a world in which $\pi = 3/4$:
<<Exploration1.2.26, cache=TRUE>>=
Bottled.null <- do(1000) * rflip(27, 3/4)
head(Bottled.null, 3)
dotPlot(~ prop, data = Bottled.null, width = 1/27, cex = 3, groups = (prop >= 24/27))
@
  \item
    Strength of evidence:
<<Exploration1.2.26b>>=
prop(~ (prop >= 24/27), data = Bottled.null)
@
\end{enumerate}


\section{Alternative Measure of Strength of Evidence}

\subsection*{Example 1.3: Heart Transplant Operations}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.15$
    
    $H_a$: $\pi > 0.15$
    
    Test statistic:  $\hat p = 0.80$ (the sample proportion of 8/10)
  \item
    We simulate a world in which $\pi = 0.15$:
<<Figure1.10, cache=TRUE>>=
Heart.null <- do(1000) * rflip(10, 0.15)
head(Heart.null, 3)
mean(~ prop, data = Heart.null)
sd(~ prop, data = Heart.null)
favstats(~ prop, data = Heart.null)
dotPlot(~ prop, data = Heart.null, width = 0.1, cex = 3, groups = (prop >= 8/10))
@
  \item
    Strength of evidence:
<<Figure1.10b>>=
prop(~ (prop >= 8/10), data = Heart.null)
@
\end{enumerate}

\subsubsection*{Digging deeper into the St. George's mortality data}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.15$
    
    $H_a$: $\pi > 0.15$
    
    Test statistic:  $\hat p = 0.197$ (the sample proportion of 71/361)
  \item
    We simulate a world in which $\pi = 0.15$:
<<Figure1.11, cache=TRUE>>=
Mort1986.null <- do(1000) * rflip(361, 0.15)
head(Mort1986.null, 3)
favstats(~ prop, data = Mort1986.null)
dotPlot(~ prop, data = Mort1986.null, width = 1/361, groups = (prop >= 71/361))
@
  \item
    Strength of evidence:
<<Figure1.11b>>=
prop(~ (prop >= 71/361), data = Mort1986.null)
@
\end{enumerate}

\subsubsection*{An alternative to the p-value: Standardized value of a statistic}

\R\ can be used as a calculator so we can compute the \term{z-score} manually:
<<Example1.3, tidy=FALSE>>=
z <- (71/361 - 0.15) / 0.018; z   # z-score for sample size 361
z <-  (8/10 - 0.15)  / 0.113; z   # z-score for sample size 10
@

A very simple way to calculate the standardized statistic, find the p-value, and plot the bell-shaped curve is with the \function{xpnorm()} function. We'll examine \function{xpnorm} in more detail later but for now, we just define a vector of quantiles (z-scores), \argument{mean}, and \argument{sd}.
<<Figure1.12, opts.label="fig4">>=
xpnorm(c(-3, -2, -1.5, 0, 1.5, 2, 3), mean = 0, sd = 1)
@

In the example above, we input standardized values. However, we can input non-standardized statistics (observed statistic) with a new \argument{mean} and \argument{sd} in order to calculate the z-score.
<<Example1.3b>>=
xpnorm(71/361, mean = 0.15, sd = 0.018, plot = FALSE)
xpnorm(8/10, mean = 0.15, sd = 0.113, plot = FALSE)
@
We'll ignore the p-values and plots for now and just realize that \function{xpnorm} has computed the z-score for us so that we do not need to manually compute z by using \R\ as a calculator.


\subsection*{Exploration 1.3: Do People Use Facial Prototyping?}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi > 0.5 $
    
    Test statistic:  $\hat p = 0.6$ (the sample proportion of 18/30 for a fictitious class)
  \item
  	We simulate a world in which $\pi = 0.5$:
<<Exploration1.3.7, cache=TRUE>>=
Tim.null <- do(1000) * rflip(30, 0.5)
head(Tim.null, 3)
dotPlot(~ prop, data = Tim.null, width = 1/30, cex =3, groups = (prop >= 18/30))
@
  \item
    Strength of evidence:
<<Exploration1.3.7b>>=
prop(~ (prop >=18/30), data = Tim.null)
@
\end{enumerate}

<<Exploration1.3.8>>=
mean(~ prop, data = Tim.null)
sd <- sd(~ prop, data = Tim.null); sd # assign the standard deviation to sd
z <- (0.6 - 0.5) / sd; z # z-score using the assigned sd
@

Again, we can input the observed statistic, mean, and standard deviation to \function{xpnorm()} for the standardized statistic:
<<Figure1.13, opts.label="fig4">>=
xpnorm(0.6, mean = 0.5, sd = sd, plot = FALSE)
@


\section{What Impacts Strength of Evidence?}

\subsection*{Example 1.4: Predicting Elections from Faces?}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi > 0.5$
    
    Test statistic:  $\hat p = 0.719$ (the sample proportion of 23/32)
  \item
    We simulate a world in which $\pi = 0.5$:
<<Figure1.14, cache=TRUE>>=
Senate.null <- do(1000) * rflip(32, 0.5)
head(Senate.null, 3)
favstats(~ prop, data = Senate.null)
dotPlot(~ prop, data = Senate.null, groups = (prop >= 23/32), width = 1/32, cex = 3)
@
  \item
    Strength of evidence:
<<Figure1.14b>>=
prop(~ (prop >= 23/32), data = Senate.null)
@
    Strength of evidence with the standardized statistic:
<<Figure1.14c>>=
mean(~ prop, data = Senate.null)
sd <- sd(~ prop, data = Senate.null); sd
xpnorm(23/32, 0.5, sd, plot = FALSE)
@
\end{enumerate}

\subsection*{What impacts strength of evidence?}

<<Figure1.15, cache=TRUE, opts.label="fig3">>=
senate.32 <- do(1000) * rflip(32, 0.5)
dotPlot(~ prop, data = senate.32, xlim = c(0.1, 0.9), cex = 5)

senate.128 <- do(1000) * rflip(128, 0.5)
dotPlot(~ prop, data = senate.128, xlim = c(0.1, 0.9), cex = 5)

senate.256 <- do(1000) * rflip(256, 0.5)
dotPlot(~ prop, data = senate.256, xlim = c(0.1, 0.9), cex = 5)
@

<<Figure1.15b>>=
sd(~ prop, data = senate.32)
sd(~ prop, data = senate.128)
sd(~ prop, data = senate.256)
@

<<Figure1.15c>>=
prop(~ (prop >= 23/32), data = senate.32)
prop(~ (prop >= 23/32), data = senate.128)
prop(~ (prop >= 23/32), data = senate.256)
@

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi \neq 0.5$
    
    Test statistic:  $\hat p = 0.719$ (the sample proportion of 23/32)
  \item
    We use the simulated world in which $\pi = 0.5$:
<<Figure1.16, tidy=FALSE>>=
dotPlot(~ prop, data = Senate.null, groups = (prop >= 23/32 | prop <= 9/32), 
        width = 1/32, cex = 3)
@
Notice that because we are doing a two-sided test, we differentiate the samples with proportions greater than or equal to  23/32 and proportions less than or equal to 9/32 (the proportion that is as extreme as 23/32) by using the bar $|$.
  \item
    Strength of evidence:
<<Figure1.16b>>=
prop(~(prop <= 9/32 | prop >= 23/32), data = Senate.null)
@
\end{enumerate}

\subsubsection*{Follow-up Study}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi \neq 0.5$
    
		Test statistic:  $\hat p = 0.677$ (the sample proportion of 189/279)
	\item
		We simulate a world in which $\pi = 0.5$:
<<Figure1.17, cache=TRUE>>=
House.null <- do(1000) * rflip(279, 0.5)
head(House.null, 3)
favstats(~ prop, data = House.null)
dotPlot(~ prop, data = House.null, groups = (prop >= 189/279 | prop <=90/279), width = 0.007)
@
  \item
    Strength of evidence:
<<Figure1.17b>>=
prop(~ (prop >= 189/279 | prop <=90/279), data = House.null)
@
    Strength of evidence with the standardized statistic:
<<Figure1.17c>>=
mean(~ prop, data = House.null)
sd <- sd(~ prop, data = House.null); sd
xpnorm(189/279, 0.5, sd, plot = FALSE)
@
\end{enumerate}

\subsection*{Exploration 1.4: Competitive Advantage to Uniform Colors?}


\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi > 0.5$
    
		Test statistic:  $\hat p = 0.543$ (the sample proportion of 248/457)
	\item
		We simulate a world in which $\pi = 0.5$:
<<Exploration1.4.3,cache=TRUE>>=
Red.null <- do(1000) * rflip(457, 0.5)
head(Red.null, 3)
favstats(~ prop, data = Red.null)
dotPlot(~ prop, data = Red.null, groups = (prop >= 0.543), width = 2/457)
@
  \item
    Strength of evidence:
<<Exploration1.4.3b>>=
prop(~ (prop >=0.543), data = Red.null)
@
\end{enumerate}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi \neq 0.5$
    
  	Test statistic:  $\hat p = 0.543$ (the sample proportion of 248/457)
	\item
		We use the simulated world in which $\pi = 0.5$ from the one-sided test:
<<Exploration1.4.5>>=
dotPlot(~ prop, data = Red.null, groups = (prop <=0.457 | prop >= 0.543), width = 2/457)
@
  \item
    Strength of evidence:
<<Exploration1.4.5b>>=
prop(~ (prop <=0.457 | prop >= 0.543), data = Red.null)
@
\end{enumerate}

\subsubsection*{Difference between statistic and null hypothesis parameter value}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi > 0.5$
    
  	Test statistic:  $\hat p = 0.57$ (the sample proportion)
	\item
		We use the simulated world in which $\pi = 0.5$:
<<Exploration1.4.6>>=
dotPlot(~ prop, data = Red.null, groups = (prop >= 0.57), width = 2/457)
@
  \item
    Strength of evidence:    
<<Exploration1.4.6b>>=
prop(~ (prop >=0.57), data = Red.null)
@
\end{enumerate}

\subsubsection*{Sample size}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi > 0.5$
    
    Test statistic:  $\hat p = 0.551$ (the sample proportion of 150/272)
	\item
		We simulate a world in which $\pi = 0.5$:
<<Exploration1.4.7, cache=TRUE>>=
Box.null <- do(1000) * rflip(272, 0.5)
head(Box.null, 3)
favstats(~ prop, data = Box.null)
dotPlot(~ prop, data = Box.null, groups = (prop >= 0.551), width = 1/272)
@
  \item
    Strength of evidence
<<Exploration1.4.7b>>=
prop(~ (prop >=0.551), data = Box.null)
@
\end{enumerate}


\section{Inference on a single proportion: Theory-based approach}

%Figure 1.18 (skip)

\subsection*{Example 1.5: Halloween Treats}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi \neq 0.5$
    
    Test statistic:  $\hat p = 0.523$ (the sample proportion of 148/283)
  \item
		We simulate a world in which $\pi = 0.5$:
<<Figure1.19, cache=TRUE>>=
Candy.null <- do(1000) * rflip(283, 0.5)
head(Candy.null, 3)
favstats(~ prop, data = Candy.null)
dotPlot(~ prop, data = Candy.null, width = 1/283)
@
\end{enumerate}

\subsubsection*{Theory-based approach (One proportion z test)}

Calculating predicted standard deviation:
<<Example1.5>>=
mean <- 0.5
n <- 283
sd <- sqrt(mean * (1 - mean) / n); sd
@

Calculating z-score:
<<Example1.5b>>=
z <- (0.523 - mean) / sd; z
xpnorm(148/283, 0.5, sd, plot = FALSE)
@

To overlay a normal approximation, let's graph a histogram using \function{histogram()} instead of a dotplot:
<<Figure1.20, opts.label="fig3", message=FALSE>>=
histogram(~ prop, data = Candy.null)
histogram(~ prop, data = Candy.null, fit = "normal")
histogram(~ prop, data = Candy.null, fit = "normal", group = cut(prop, c(0, 135/283, 148/283, 1)), fcol=c("steelblue", "navy", "steelblue"))

prop(~ (prop <= 135/283 | prop >= 148/283), data = Candy.null)
@
%help with histogram grouping

The two main functions we need for working with normal distributions are \function{pnorm} and \function{qnorm}.
\function{pnorm} computes the proportion of a normal distribution below a specified value:


\[
\mbox{\texttt{pnorm(x,mean=$\mu$, sd=$\sigma$)}} = \Prob(X \le x)
\]
when $X \sim \Norm(\mu, \sigma)$.

We can obtain arbitrary probabilities using \verb!pnorm()!
%copied from Lock5
We can now examine the rest of the output from \function{xpnorm}, which is an augmented version of \function{pnorm}. Because it's a two-sided test, we can input both the observed statistic (148/283) and the statistic that is as extreme as the observed (135/283). 
<<Figure1.20b, opts.label="fig4">>=
xpnorm(c(135/283, 148/283), 0.5, sd)
@
The output gives the z-scores for both statistics and the p-value. We know now that this p-value is found using the predicted standard deviation and normal approximation. The p-value for the two-sided test is the sum of P($Z <= -0.773$) and P($Z >  0.773$). 

We can also use the just observed statistic as we have done before but only we will need to change the \argument{lower.tail} to \option{FALSE}.
<<Figure1.20c, >>=
xpnorm(148/283, 0.5, sd, lower.tail = FALSE, plot = FALSE)
2 * xpnorm(148/283, 0.5, sd, lower.tail = FALSE, plot = FALSE)
@
This results in the p-value of the alternative hypothsis that $\pi$ is greater than the observed statistic (the default is the alternative hypothsis that $\pi$ is less than the observed statistic). For the two-sided test, we have multiplied the resulting p-value by two.

The function \function{pnorm()} can be used just to find the p-value:
<<Figure1.20d>>=
2 * pnorm(148/283, 0.5, sd, lower.tail = FALSE)
@

Further, we can input the standardized statistic (z-score) to find the p-value: 
<<Figure1.20e>>=
2 * pnorm(z, 0, 1, lower.tail = FALSE)
@

The most convenient way to find the p-value for a proportion using normal approximation is to use \function{prop.test()} by inputing the number of sucesses and the number of samples:
<<Example1.5c>>=
prop.test(148, n = 283)
@
Note that the default for the prop test is with a $\pi=0.5$, two-sided test, and a continuity correction. The continuity correction results in a more accurate p-value but if you want the p-value found with \function{pnorm()} we can change the default.

<<Figure1.5d>>=
prop.test(148, 283, correct = FALSE)
@

\subsubsection*{A situation where a theory-based approach doesn't work}

<<Example1.5e>>=
mean <- 1/3
n <- 12
sd <- sqrt(mean * (1 - mean) / n); sd
@

<<Figure1.21>>=
dotPlot(~ prop, data = RPS.null, group = (prop <= 1/6), width = 1/12, cex = 3)
prop(~ (prop <= 1/6), data = RPS.null)
@

<<Figure1.21b, opts.label="fig4">>=
xpnorm(1/6, 1/3, sd)
@


\subsection*{Exploration 1.5: Calling Heads or Tails}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi > 0.5$
    
    Test statistic:  $\hat p = 0.651$ (the sample proportion of 54/83)
  \item
  	We simulate a world in which $\pi = 0.5$:
<<Exploration1.5.5,cache=TRUE>>=
Heads.null <- do(1000) * rflip(83, 0.5)
head(Heads.null, 3)
favstats(~ prop, data = Heads.null)
histogram(~ prop, data = Heads.null, groups = (prop >= 54/83), fit = "normal")
@
  \item
    Strength of evidence
<<Exploration1.5.5b>>=
prop(~ (prop >= 54/83), data = Heads.null)
@
    Normal approximation using simulated sd:
<<Exploration1.5.5c, opts.label="fig4">>=
sd <- sd(~ prop, data = Heads.null)
xpnorm(54/83, 0.5, sd, lower.tail=FALSE)
@
\end{enumerate}

\subsubsection*{Formulas}

<<Exploration1.5.8>>=
sd <- sqrt(0.5 * (1 - 0.5) / 83); sd
@

<<Exploration1.5.9>>=
xpnorm(54/83, 0.5, sd, plot = FALSE, lower.tail = FALSE)
prop.test(54, 83, alt = "greater", correct = FALSE)
@

<<Exploration1.5.10, include=FALSE>>=
<<Exploration1.5.9>>
@

\subsubsection*{Follow-up Analysis \#1}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi \neq 0.5$
    
    Test statistic:  $\hat p = 0.70$ (the sample proportion)
  \item
    Normal approximation using predicted sd:
<<Exploration1.5.12>>=
sd <- sqrt(0.5 * (1 - 0.5) / 83); sd
2 * xpnorm(0.70, 0.5, sd, plot = FALSE, lower.tail = FALSE)
@
    Approximate test for proportions without continuity correction:
<<Exploration1.5.12b>>=
prop.test(58.1, 83, correct = FALSE) # 58.1 = 0.70 * 83
@
\end{enumerate}

\subsubsection*{Follow-up Analysis \# 2}

\begin{enumerate}
  \item
    $H_0$: $\pi = 0.5$
    
    $H_a$: $\pi \neq 0.5$
    
    Test statistic:  $\hat p = 0.875$ (the sample proportion of 7/8)
  \item
    We simulate a world in which $\pi = 0.5$:
<<Exploration1.5.13, cache=TRUE>>=
Small.null <- do(1000) * rflip(8, 0.5)
head(Small.null, 3)
dotPlot(~ prop, data = Small.null, groups = (prop <= 0.125 | prop >= 0.875), width = 1/8, cex = 3)
@
  \item
    Strength of evidence:
<<Exploration1.5.13b>>=
prop(~ (prop <= 0.125 | prop >= 0.875), data = Small.null)
@
    Approximate test for proportions without continuity correction:
<<Exploration1.5.13c, warning=FALSE>>=
prop.test(7, 8, correct = FALSE)
@
\end{enumerate}

There is also another test that will compute the p-value for a proportion and that the binomial test. \function{binom.test()} utilizes a binomial probability distribution while \function{prop.test()} utilizes a normal probability distribution. The tests are similar but the binomial test will result in the most accurate p-value.
<<>>=
binom.test(7, 8)
binom.test(58, 83)
@
